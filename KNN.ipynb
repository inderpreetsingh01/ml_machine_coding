{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNv2Eed7q7lEzn/DUgUOmtc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inderpreetsingh01/ml_machine_coding/blob/main/KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5CN4Qc9DuVIP"
      },
      "outputs": [],
      "source": [
        "# classification\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "class KNNClassifier:\n",
        "    def __init__(self, k=3, distance='euclidean'):\n",
        "        self.k = k\n",
        "        self.distance = distance\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def _compute_distance(self, x1, x2):\n",
        "        if self.distance == 'euclidean':\n",
        "            return np.sqrt(np.sum((x1 - x2) ** 2))\n",
        "        elif self.distance == 'manhattan':\n",
        "            return np.sum(np.abs(x1 - x2))\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported distance metric\")\n",
        "\n",
        "    def _predict_one(self, x):\n",
        "        distances = [self._compute_distance(x, x_train) for x_train in self.X_train]\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
        "        most_common = Counter(k_nearest_labels).most_common(1)\n",
        "        return most_common[0][0]\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_one(x) for x in X])\n",
        "\n",
        "    def score(self, X, y):\n",
        "        preds = self.predict(X)\n",
        "        return np.mean(preds == y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize features (very important for distance-based models!)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Fit KNN\n",
        "knn = KNNClassifier(k=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "acc = knn.score(X_test, y_test)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb7VKohZuZtI",
        "outputId": "e5325802-1ca5-404a-f82e-e23c962c7e51"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_67WfF8TueWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sbuTJCvgufSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# weighted KNN\n",
        "class KNNClassifier:\n",
        "    def __init__(self, k=3, distance='euclidean', weighted=False):\n",
        "        self.k = k\n",
        "        self.distance = distance\n",
        "        self.weighted = weighted\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def _compute_distance(self, x1, x2):\n",
        "        if self.distance == 'euclidean':\n",
        "            return np.sqrt(np.sum((x1 - x2) ** 2))\n",
        "        elif self.distance == 'manhattan':\n",
        "            return np.sum(np.abs(x1 - x2))\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported distance metric\")\n",
        "\n",
        "    def _predict_one(self, x):\n",
        "        distances = np.array([self._compute_distance(x, x_train) for x_train in self.X_train])\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        k_labels = [self.y_train[i] for i in k_indices]\n",
        "\n",
        "        if not self.weighted:\n",
        "            # Unweighted majority vote\n",
        "            return Counter(k_labels).most_common(1)[0][0]\n",
        "        else:\n",
        "            # Weighted vote (closer = more weight)\n",
        "            weights = 1 / (distances[k_indices] + 1e-5)  # avoid div by zero\n",
        "            label_weights = {}\n",
        "            for label, weight in zip(k_labels, weights):\n",
        "                label_weights[label] = label_weights.get(label, 0) + weight\n",
        "            return max(label_weights.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_one(x) for x in X])\n",
        "\n",
        "    def score(self, X, y):\n",
        "        preds = self.predict(X)\n",
        "        return np.mean(preds == y)"
      ],
      "metadata": {
        "id": "LRu8ybngufRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pwHjY8T0ufPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN Regressor\n",
        "class KNNRegressor:\n",
        "    def __init__(self, k=3, distance='euclidean', weighted=False):\n",
        "        self.k = k\n",
        "        self.distance = distance\n",
        "        self.weighted = weighted\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def _compute_distance(self, x1, x2):\n",
        "        if self.distance == 'euclidean':\n",
        "            return np.sqrt(np.sum((x1 - x2) ** 2))\n",
        "        elif self.distance == 'manhattan':\n",
        "            return np.sum(np.abs(x1 - x2))\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported distance metric\")\n",
        "\n",
        "    def _predict_one(self, x):\n",
        "        distances = np.array([self._compute_distance(x, x_train) for x_train in self.X_train])\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        k_values = [self.y_train[i] for i in k_indices]\n",
        "\n",
        "        if not self.weighted:\n",
        "            return np.mean(k_values)\n",
        "        else:\n",
        "            weights = 1 / (distances[k_indices] + 1e-5)\n",
        "            return np.sum(weights * k_values) / np.sum(weights)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_one(x) for x in X])\n",
        "\n",
        "    def score(self, X, y):\n",
        "        preds = self.predict(X)\n",
        "        return 1 - np.sum((preds - y) ** 2) / np.sum((y - np.mean(y)) ** 2)  # R² score"
      ],
      "metadata": {
        "id": "C9iz5GzaufME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RPEWEfasufI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris, load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# For classification\n",
        "X_cls, y_cls = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_cls, y_cls, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "knn_cls = KNNClassifier(k=5, weighted=True)\n",
        "knn_cls.fit(X_train, y_train)\n",
        "print(\"Weighted KNN Classifier Accuracy:\", knn_cls.score(X_test, y_test))\n",
        "\n",
        "# For regression (use any regression dataset like California housing, or Boston if available)\n",
        "X_reg, y_reg = load_boston(return_X_y=True)  # use fetch_california_housing in newer sklearn\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "knn_reg = KNNRegressor(k=5, weighted=True)\n",
        "knn_reg.fit(X_train, y_train)\n",
        "print(\"Weighted KNN Regressor R² Score:\", knn_reg.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "3azY57c1usmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L0klwaDBusin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cosine similarity\n",
        "\n",
        "class KNNClassifier:\n",
        "    def __init__(self, k=3, distance='euclidean', weighted=False):\n",
        "        self.k = k\n",
        "        self.distance = distance\n",
        "        self.weighted = weighted\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def _compute_distance(self, x1, x2):\n",
        "        if self.distance == 'euclidean':\n",
        "            return np.sqrt(np.sum((x1 - x2) ** 2))\n",
        "        elif self.distance == 'manhattan':\n",
        "            return np.sum(np.abs(x1 - x2))\n",
        "        elif self.distance == 'cosine':\n",
        "            norm1 = np.linalg.norm(x1)\n",
        "            norm2 = np.linalg.norm(x2)\n",
        "            if norm1 == 0 or norm2 == 0:\n",
        "                return 1.0  # Max distance if zero vector\n",
        "            cosine_similarity = np.dot(x1, x2) / (norm1 * norm2)\n",
        "            return 1 - cosine_similarity\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported distance metric\")\n",
        "\n",
        "    def _predict_one(self, x):\n",
        "        distances = np.array([self._compute_distance(x, x_train) for x_train in self.X_train])\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        k_labels = [self.y_train[i] for i in k_indices]\n",
        "\n",
        "        if not self.weighted:\n",
        "            return Counter(k_labels).most_common(1)[0][0]\n",
        "        else:\n",
        "            weights = 1 / (distances[k_indices] + 1e-5)\n",
        "            label_weights = {}\n",
        "            for label, weight in zip(k_labels, weights):\n",
        "                label_weights[label] = label_weights.get(label, 0) + weight\n",
        "            return max(label_weights.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_one(x) for x in X])\n",
        "\n",
        "    def score(self, X, y):\n",
        "        preds = self.predict(X)\n",
        "        return np.mean(preds == y)"
      ],
      "metadata": {
        "id": "fd7yS9fzushg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CRp037Byusgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nul8utbeHOra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KDNode:\n",
        "    def __init__(self, point, axis, left=None, right=None):\n",
        "        self.point = point       # A list/tuple like [x, y]\n",
        "        self.axis = axis         # Splitting axis (0 for x, 1 for y, etc.)\n",
        "        self.left = left         # KDNode\n",
        "        self.right = right       # KDNode"
      ],
      "metadata": {
        "id": "iqynxav1usbs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class KDTree:\n",
        "    def __init__(self, points):\n",
        "        self.k = len(points[0]) if points else 0  # dimensionality\n",
        "        self.root = self._build(points)\n",
        "\n",
        "    def _build(self, points, depth=0):\n",
        "        if not points:\n",
        "            return None\n",
        "\n",
        "        axis = depth % self.k\n",
        "        points.sort(key=lambda x: x[axis])\n",
        "        median = len(points) // 2\n",
        "\n",
        "        return KDNode(\n",
        "            point=points[median],\n",
        "            axis=axis,\n",
        "            left=self._build(points[:median], depth + 1),\n",
        "            right=self._build(points[median + 1:], depth + 1)\n",
        "        )\n",
        "\n",
        "    def nearest_neighbor(self, target):\n",
        "        best = [None, float('inf')]  # [best_point, best_distance]\n",
        "\n",
        "        def _search(node):\n",
        "            if node is None:\n",
        "                return\n",
        "\n",
        "            point = node.point\n",
        "            axis = node.axis\n",
        "            dist = np.linalg.norm(np.array(point) - np.array(target))\n",
        "\n",
        "            # Update best match if needed\n",
        "            if dist < best[1]:\n",
        "                best[0], best[1] = point, dist\n",
        "\n",
        "            # Choose direction to search\n",
        "            diff = target[axis] - point[axis]\n",
        "            close, away = (node.left, node.right) if diff < 0 else (node.right, node.left)\n",
        "\n",
        "            _search(close)\n",
        "\n",
        "            # Check if we need to search the other side\n",
        "            if abs(diff) < best[1]:\n",
        "                _search(away)\n",
        "\n",
        "        _search(self.root)\n",
        "        return best[0], best[1]"
      ],
      "metadata": {
        "id": "fjS-pso8woxv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    points = [\n",
        "        [2, 3],\n",
        "        [5, 4],\n",
        "        [9, 6],\n",
        "        [4, 7],\n",
        "        [8, 1],\n",
        "        [7, 2]\n",
        "    ]\n",
        "    target = [9, 2]\n",
        "\n",
        "    tree = KDTree(points)\n",
        "    nearest_point, distance = tree.nearest_neighbor(target)\n",
        "    print(f\"Nearest to {target}: {nearest_point} (distance = {distance:.3f})\")"
      ],
      "metadata": {
        "id": "jOJ41-Rpwtiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H5fwRTUTYoWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with insert operation as well\n",
        "class KDNode:\n",
        "    def __init__(self, point, axis, left=None, right=None):\n",
        "        self.point = point\n",
        "        self.axis = axis\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "\n",
        "class KDTree:\n",
        "    def __init__(self, points=None):\n",
        "        self.k = len(points[0]) if points else 2  # default to 2D\n",
        "        self.root = self._build(points) if points else None\n",
        "\n",
        "    def _build(self, points, depth=0):\n",
        "        if not points:\n",
        "            return None\n",
        "\n",
        "        axis = depth % self.k\n",
        "        points.sort(key=lambda x: x[axis])\n",
        "        median = len(points) // 2\n",
        "\n",
        "        return KDNode(\n",
        "            point=points[median],\n",
        "            axis=axis,\n",
        "            left=self._build(points[:median], depth + 1),\n",
        "            right=self._build(points[median + 1:], depth + 1)\n",
        "        )\n",
        "\n",
        "    def insert(self, point):\n",
        "        def _insert(node, point, depth):\n",
        "            if node is None:\n",
        "                return KDNode(point, depth % self.k)\n",
        "\n",
        "            axis = node.axis\n",
        "            if point[axis] < node.point[axis]:\n",
        "                node.left = _insert(node.left, point, depth + 1)\n",
        "            else:\n",
        "                node.right = _insert(node.right, point, depth + 1)\n",
        "\n",
        "            return node\n",
        "\n",
        "        if self.root is None:\n",
        "            self.root = KDNode(point, axis=0)\n",
        "        else:\n",
        "            _insert(self.root, point, 0)\n",
        "\n",
        "    def nearest_neighbor(self, target):\n",
        "        best = [None, float('inf')]\n",
        "\n",
        "        def _search(node):\n",
        "            if node is None:\n",
        "                return\n",
        "\n",
        "            point = node.point\n",
        "            axis = node.axis\n",
        "            dist = np.linalg.norm(np.array(point) - np.array(target))\n",
        "\n",
        "            if dist < best[1]:\n",
        "                best[0], best[1] = point, dist\n",
        "\n",
        "            diff = target[axis] - point[axis]\n",
        "            close, away = (node.left, node.right) if diff < 0 else (node.right, node.left)\n",
        "\n",
        "            _search(close)\n",
        "            if abs(diff) < best[1]:\n",
        "                _search(away)\n",
        "\n",
        "        _search(self.root)\n",
        "        return best[0], best[1]\n"
      ],
      "metadata": {
        "id": "weOvSTOGYoV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    tree = KDTree([[3, 6], [17, 15], [13, 15], [6, 12], [9, 1], [2, 7], [10, 19]])\n",
        "\n",
        "    print(\"Before insert:\")\n",
        "    nearest = tree.nearest_neighbor([9, 2])\n",
        "    print(f\"Nearest to [9, 2]: {nearest}\")\n",
        "\n",
        "    tree.insert([8, 3])\n",
        "    print(\"\\nAfter insert [8, 3]:\")\n",
        "    nearest = tree.nearest_neighbor([9, 2])\n",
        "    print(f\"Nearest to [9, 2]: {nearest}\")"
      ],
      "metadata": {
        "id": "tHmj1noAYoQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Notes on Insertions\n",
        "# ✅ Works recursively like BST insert, with axis cycling.\n",
        "# ❌ Does not rebalance the tree — over time, the tree may degrade in performance.\n",
        "# To fix this, you’d need rebuilding periodically or use balanced KD-Tree variants."
      ],
      "metadata": {
        "id": "WUpU2-9sYxQK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}