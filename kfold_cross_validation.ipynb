{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZcDBakd9DT9OYpQn3F7fP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inderpreetsingh01/ml_machine_coding/blob/main/kfold_cross_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HKvrH0AOi-UG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def k_fold_split(X, y, k=5, shuffle=True, seed=None):\n",
        "    \"\"\"\n",
        "    Splits data into k folds\n",
        "    \"\"\"\n",
        "    n_samples = len(X)\n",
        "    indices = np.arange(n_samples)\n",
        "\n",
        "    if shuffle:\n",
        "        rng = np.random.default_rng(seed)\n",
        "        rng.shuffle(indices)\n",
        "\n",
        "    fold_sizes = np.full(k, n_samples // k, dtype=int)\n",
        "    fold_sizes[:n_samples % k] += 1  # distribute remainder\n",
        "    current = 0\n",
        "    folds = []\n",
        "    for fold_size in fold_sizes:\n",
        "        start, stop = current, current + fold_size\n",
        "        folds.append(indices[start:stop])\n",
        "        current = stop\n",
        "    return folds\n",
        "\n",
        "\n",
        "def k_fold_cross_validation(model_class, X, y, k=5, metric=\"accuracy\", **model_params):\n",
        "    \"\"\"\n",
        "    Perform K-Fold Cross Validation\n",
        "    - model_class: class of model (must implement fit, predict)\n",
        "    - X: features (numpy array)\n",
        "    - y: labels\n",
        "    - k: number of folds\n",
        "    - metric: \"accuracy\", \"f1\", \"precision\", \"recall\"\n",
        "    - model_params: params to initialize the model\n",
        "    \"\"\"\n",
        "    folds = k_fold_split(X, y, k)\n",
        "    scores = []\n",
        "\n",
        "    for i in range(k):\n",
        "        # Prepare train/validation split\n",
        "        val_idx = folds[i]\n",
        "        train_idx = np.hstack([folds[j] for j in range(k) if j != i])\n",
        "        X_train, y_train = X[train_idx], y[train_idx]\n",
        "        X_val, y_val = X[val_idx], y[val_idx]\n",
        "\n",
        "        # Train model\n",
        "        model = model_class(**model_params)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Predictions\n",
        "        y_pred = model.predict(X_val)\n",
        "\n",
        "        # Metric\n",
        "        if metric == \"accuracy\":\n",
        "            score = np.mean(y_pred == y_val)\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Metric {metric} not yet implemented\")\n",
        "        scores.append(score)\n",
        "        print(f\"Fold {i+1}/{k}: {metric} = {score:.4f}\")\n",
        "\n",
        "    print(f\"Mean {metric}: {np.mean(scores):.4f}\")\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Logistic Regression using numpy\n",
        "class LogisticRegression:\n",
        "    def __init__(self, lr=0.1, n_iter=1000):\n",
        "        self.lr = lr\n",
        "        self.n_iter = n_iter\n",
        "\n",
        "    def _sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.n_iter):\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "            y_pred = self._sigmoid(linear_model)\n",
        "\n",
        "            # Gradient descent\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n",
        "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
        "\n",
        "            self.weights -= self.lr * dw\n",
        "            self.bias -= self.lr * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        y_pred = self._sigmoid(linear_model)\n",
        "        return np.where(y_pred >= 0.5, 1, 0)"
      ],
      "metadata": {
        "id": "gFQ8Z0F1jXGr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy dataset\n",
        "X = np.array([[0],[1],[2],[3],[4],[5],[6],[7],[8],[9]])\n",
        "y = np.array([0,0,0,0,1,1,1,1,1,1])\n",
        "\n",
        "# Run 5-fold CV\n",
        "scores = k_fold_cross_validation(LogisticRegression, X, y, k=5, metric=\"accuracy\", lr=0.1, n_iter=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoQK_BApjZXE",
        "outputId": "5901befe-6095-4e35-a89f-aa4a4e40bf61"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/5: accuracy = 1.0000\n",
            "Fold 2/5: accuracy = 0.5000\n",
            "Fold 3/5: accuracy = 1.0000\n",
            "Fold 4/5: accuracy = 1.0000\n",
            "Fold 5/5: accuracy = 1.0000\n",
            "Mean accuracy: 0.9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pQkf4n5djdl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1cnlnJYJk9ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Classification Metrics =====\n",
        "def accuracy_score(y_true, y_pred):\n",
        "    return np.mean(y_true == y_pred)\n",
        "\n",
        "def precision_score(y_true, y_pred):\n",
        "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    return tp / (tp + fp + 1e-10)\n",
        "\n",
        "def recall_score(y_true, y_pred):\n",
        "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
        "    return tp / (tp + fn + 1e-10)\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    p = precision_score(y_true, y_pred)\n",
        "    r = recall_score(y_true, y_pred)\n",
        "    return 2 * p * r / (p + r + 1e-10)\n",
        "\n",
        "def roc_auc_score(y_true, y_prob):\n",
        "    \"\"\"Compute ROC-AUC using trapezoidal integration\"\"\"\n",
        "    desc_score_indices = np.argsort(-y_prob)\n",
        "    y_true = y_true[desc_score_indices]\n",
        "\n",
        "    tpr = []\n",
        "    fpr = []\n",
        "    P = np.sum(y_true == 1)\n",
        "    N = np.sum(y_true == 0)\n",
        "    tp, fp = 0, 0\n",
        "\n",
        "    for i in range(len(y_true)):\n",
        "        if y_true[i] == 1:\n",
        "            tp += 1\n",
        "        else:\n",
        "            fp += 1\n",
        "        tpr.append(tp / P)\n",
        "        fpr.append(fp / N)\n",
        "\n",
        "    return np.trapz(np.array(tpr), np.array(fpr))\n",
        "\n",
        "def top_k_accuracy_score(y_true, y_pred_probs, k=3):\n",
        "    top_k_preds = np.argsort(y_pred_probs, axis=1)[:, -k:]\n",
        "    hits = np.array([y_true[i] in top_k_preds[i] for i in range(len(y_true))])\n",
        "    return np.mean(hits)\n",
        "\n",
        "\n",
        "# ===== Regression Metrics =====\n",
        "def mse(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "def mae(y_true, y_pred):\n",
        "    return np.mean(np.abs(y_true - y_pred))\n",
        "\n",
        "def r2_score(y_true, y_pred):\n",
        "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
        "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
        "    return 1 - ss_res / (ss_tot + 1e-10)"
      ],
      "metadata": {
        "id": "R3WVaIHXk9cc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def k_fold_split(X, y, k=5, shuffle=True, seed=None):\n",
        "    n_samples = len(X)\n",
        "    indices = np.arange(n_samples)\n",
        "\n",
        "    if shuffle:\n",
        "        rng = np.random.default_rng(seed)\n",
        "        rng.shuffle(indices)\n",
        "\n",
        "    fold_sizes = np.full(k, n_samples // k, dtype=int)\n",
        "    fold_sizes[:n_samples % k] += 1\n",
        "    folds, current = [], 0\n",
        "    for fold_size in fold_sizes:\n",
        "        start, stop = current, current + fold_size\n",
        "        folds.append(indices[start:stop])\n",
        "        current = stop\n",
        "    return folds\n",
        "\n",
        "\n",
        "def k_fold_cross_validation(model_class, X, y, k=5, metric=accuracy_score, **model_params):\n",
        "    \"\"\"\n",
        "    - model_class: must implement fit(), predict(), optionally predict_proba()\n",
        "    - metric: metric function\n",
        "    - Works for classification & regression\n",
        "    \"\"\"\n",
        "    folds = k_fold_split(X, y, k)\n",
        "    scores = []\n",
        "\n",
        "    for i in range(k):\n",
        "        val_idx = folds[i]\n",
        "        train_idx = np.hstack([folds[j] for j in range(k) if j != i])\n",
        "        X_train, y_train = X[train_idx], y[train_idx]\n",
        "        X_val, y_val = X[val_idx], y[val_idx]\n",
        "\n",
        "        # Train model\n",
        "        model = model_class(**model_params)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Predictions\n",
        "        if metric == roc_auc_score or metric == top_k_accuracy_score:\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                y_pred = model.predict_proba(X_val)\n",
        "            else:\n",
        "                raise ValueError(\"Model must implement predict_proba for ROC-AUC/Top-K\")\n",
        "        else:\n",
        "            y_pred = model.predict(X_val)\n",
        "\n",
        "        # Compute metric\n",
        "        if metric == top_k_accuracy_score:\n",
        "            score = metric(y_val, y_pred, k=3)\n",
        "        elif metric == roc_auc_score:\n",
        "            score = metric(y_val, y_pred[:, 1])\n",
        "        else:\n",
        "            score = metric(y_val, y_pred)\n",
        "\n",
        "        scores.append(score)\n",
        "        print(f\"Fold {i+1}/{k}: {metric.__name__} = {score:.4f}\")\n",
        "\n",
        "    print(f\"Mean {metric.__name__}: {np.mean(scores):.4f}\")\n",
        "    return scores"
      ],
      "metadata": {
        "id": "SVcV9cDok9ac"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy dataset\n",
        "X = np.array([[0],[1],[2],[3],[4],[5],[6],[7],[8],[9]])\n",
        "y = np.array([0,0,0,0,1,1,1,1,1,1])\n",
        "\n",
        "class LogisticRegression:\n",
        "    def __init__(self, lr=0.1, n_iter=1000):\n",
        "        self.lr = lr\n",
        "        self.n_iter = n_iter\n",
        "\n",
        "    def _sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.n_iter):\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "            y_pred = self._sigmoid(linear_model)\n",
        "\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n",
        "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
        "\n",
        "            self.weights -= self.lr * dw\n",
        "            self.bias -= self.lr * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        y_pred = self._sigmoid(linear_model)\n",
        "        return np.where(y_pred >= 0.5, 1, 0)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        return np.column_stack([1 - self._sigmoid(linear_model), self._sigmoid(linear_model)])\n",
        "\n",
        "\n",
        "# Run CV with multiple metrics\n",
        "print(\"=== Accuracy ===\")\n",
        "k_fold_cross_validation(LogisticRegression, X, y, k=5, metric=accuracy_score, lr=0.1, n_iter=1000)\n",
        "\n",
        "print(\"\\n=== F1 ===\")\n",
        "k_fold_cross_validation(LogisticRegression, X, y, k=5, metric=f1_score, lr=0.1, n_iter=1000)\n",
        "\n",
        "print(\"\\n=== ROC-AUC ===\")\n",
        "k_fold_cross_validation(LogisticRegression, X, y, k=5, metric=roc_auc_score, lr=0.1, n_iter=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaGpb6Szk9X4",
        "outputId": "e9431b9e-dcc1-4aa6-92b3-2f7881be2d9b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Accuracy ===\n",
            "Fold 1/5: accuracy_score = 0.5000\n",
            "Fold 2/5: accuracy_score = 1.0000\n",
            "Fold 3/5: accuracy_score = 1.0000\n",
            "Fold 4/5: accuracy_score = 1.0000\n",
            "Fold 5/5: accuracy_score = 1.0000\n",
            "Mean accuracy_score: 0.9000\n",
            "\n",
            "=== F1 ===\n",
            "Fold 1/5: f1_score = 1.0000\n",
            "Fold 2/5: f1_score = 0.0000\n",
            "Fold 3/5: f1_score = 1.0000\n",
            "Fold 4/5: f1_score = 0.6667\n",
            "Fold 5/5: f1_score = 0.6667\n",
            "Mean f1_score: 0.6667\n",
            "\n",
            "=== ROC-AUC ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2709492513.py:39: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  fpr.append(fp / N)\n",
            "/tmp/ipython-input-2709492513.py:43: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  auc = np.trapz(tpr, fpr)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/5: roc_auc_score = nan\n",
            "Fold 2/5: roc_auc_score = 1.0000\n",
            "Fold 3/5: roc_auc_score = nan\n",
            "Fold 4/5: roc_auc_score = 1.0000\n",
            "Fold 5/5: roc_auc_score = nan\n",
            "Mean roc_auc_score: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2709492513.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  tpr.append(tp / P)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[np.float64(nan),\n",
              " np.float64(1.0),\n",
              " np.float64(nan),\n",
              " np.float64(1.0),\n",
              " np.float64(nan)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression:\n",
        "    def __init__(self, lr=0.01, n_iter=1000):\n",
        "        self.lr = lr\n",
        "        self.n_iter = n_iter\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.n_iter):\n",
        "            y_pred = np.dot(X, self.weights) + self.bias\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n",
        "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
        "            self.weights -= self.lr * dw\n",
        "            self.bias -= self.lr * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.dot(X, self.weights) + self.bias\n",
        "\n",
        "\n",
        "# Regression CV\n",
        "X = np.linspace(0, 10, 20).reshape(-1, 1)\n",
        "y = 3 * X.flatten() + 5 + np.random.randn(20)  # noisy linear relation\n",
        "\n",
        "print(\"\\n=== Linear Regression (MSE) ===\")\n",
        "k_fold_cross_validation(LinearRegression, X, y, k=5, metric=mse, lr=0.01, n_iter=1000)\n",
        "\n",
        "print(\"\\n=== Linear Regression (R2) ===\")\n",
        "k_fold_cross_validation(LinearRegression, X, y, k=5, metric=r2_score, lr=0.01, n_iter=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzpSoMMhlI6_",
        "outputId": "97fcf7c2-6555-4474-861a-d1b81a4ed895"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Linear Regression (MSE) ===\n",
            "Fold 1/5: mse = 2.0243\n",
            "Fold 2/5: mse = 1.8645\n",
            "Fold 3/5: mse = 0.3516\n",
            "Fold 4/5: mse = 0.1207\n",
            "Fold 5/5: mse = 1.9784\n",
            "Mean mse: 1.2679\n",
            "\n",
            "=== Linear Regression (R2) ===\n",
            "Fold 1/5: r2_score = 0.8521\n",
            "Fold 2/5: r2_score = 0.9912\n",
            "Fold 3/5: r2_score = 0.9834\n",
            "Fold 4/5: r2_score = 0.9688\n",
            "Fold 5/5: r2_score = 0.9878\n",
            "Mean r2_score: 0.9566\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[np.float64(0.8520538085845042),\n",
              " np.float64(0.9911521411476494),\n",
              " np.float64(0.9833944545571156),\n",
              " np.float64(0.9687506065233892),\n",
              " np.float64(0.9877911154860132)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "56F8XTswlib7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_cENwWwYllhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vhVuai2nllfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZiTQ7hX_lldc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}